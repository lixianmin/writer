

#### 1 安装+启动

1. 从https://kafka.apache.org/downloads 下载
2. 无论是组建集群，还是新加节点，都按以下方案来就可以



```shell
# 创建日志目录，一定要创建多个
sudo mkdir -p /home/disk4/data/kafka/kafka-logs
sudo chown -R batsdk /home/disk4/data/

sudo mkdir -p /home/disk5/data/kafka/kafka-logs
sudo chown -R batsdk /home/disk5/data/

# 调整server.properties
# 启动
export KAFKA_HEAP_OPTS="-Xms6G -Xmx6G"
bin/kafka-server-start.sh config/server.properties &

# 停止
bin/kafka-server-stop.sh
```



#### 2 配置

##### 01 server.properties

```ini
# 唯一标识符，整数
broker.id=8
port=9092

# 配置zookeeper地址
# 如果多个kafka集群共用一套zk，则可以考虑使用 chroot
zookeeper.connect=hello.com:2181,world.com:2181,panda.com:2181

# log参数
# 日志位置：一定配置多块磁盘，以提升读写性能，以支持failover
log.dirs=/home/disk4/data/kafka/kafka-logs,/home/disk5/data/kafka/kafka-logs
#log.retention.hours=168		# 消息被保存的最长时间，默认168h=7天
#log.retention.bytes=-1			# broker为消息保存的总磁盘容量大小，默认-1，即不限制

# follower超过10秒没向leader发起fetch请求，就从ISR中移除（满足条件后会再加入到ISR中）
#replica.lag.time.max.ms=10000	
# follower的消息落后于leader超4000条，就从ISR中移除（满足条件后会再加入到ISR中）
#replica.lag.max.messages=4000	

##################### leader参数 #####################
# 禁止进度落后的副本竞选成为leader，否则可能会导致数据丢失
unclean.leader.election.enable=false

# 禁止定期换leader
auto.leader.rebalance.enable=false

##################### topic参数 #####################
# 禁止自动创建topic，应该由运维按部门进行分配
auto.create.topics.enable=false

# 每个topic的默认分区数	
num.partitions=3

##################### 其它参数 #####################
# 单个消息的大小上限，默认值~1M，先调整为20M
message.max.bytes=20971520
```



##### 02 producer.properties（暂未调整）

```ini
# 0：异步发送，不等待leader回复，producer立即返回，消息有可能丢失
# 1：produer等待leader返回的ack消息后再返回，丢会重发
# -1：所有的follower都同步消息成功后leader才发送ack给produer，高可靠
request.required.asks=0
```









----

#### 9 References

1. [Kafka集群部署指南](https://ken.io/note/kafka-cluster-deploy-guide)
2. 