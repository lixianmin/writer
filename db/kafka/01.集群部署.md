

#### 1 安装+启动

##### 1 基于docker测试

以下内容在ice.bin下的docker-compose.yml中

```yml
version: '3.9'

# https://hub.docker.com/r/apache/kafka
# don't use kafka-native, because there is no shell scripts built in the kafka-native docker image

services:
  kafka:
    image: apache/kafka:latest
    hostname: kafka
    container_name: kafka
    ports:
      - "9092:9092"
    environment:
      KAFKA_NODE_ID: 1 # Unique ID for this Kafka node
      KAFKA_PROCESS_ROLES: broker,controller # This node acts as both broker and controller
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092,CONTROLLER://0.0.0.0:9093
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://localhost:9092
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@kafka:9093 # Node ID @ hostname:controller_port
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true" # Enable automatic topic creation
      KAFKA_NUM_PARTITIONS: 6 # Default number of partitions for new topics
      KAFKA_LOG_RETENTION_HOURS: 720 # Message retention for 720 hours (30 days)
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1 # Recommended for single-node setups
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1 # Recommended for single-node setups
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1 # Recommended for single-node setups
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER # Listener name for controller communication
    volumes:
      - kafka-data:/var/lib/kafka/data # Persist Kafka data

volumes:
  kafka-data:
```





##### 2 旧的安装方式

1. 从https://kafka.apache.org/downloads 下载
2. 无论是组建集群，还是新加节点，都按以下方案来就可以



```shell
# 创建日志目录，一定要创建多个
sudo mkdir -p /home/disk4/data/kafka/kafka-logs
sudo chown -R batsdk /home/disk4/data/

sudo mkdir -p /home/disk5/data/kafka/kafka-logs
sudo chown -R batsdk /home/disk5/data/

# 调整server.properties
# 启动
export KAFKA_HEAP_OPTS="-Xms6G -Xmx6G"
bin/kafka-server-start.sh config/server.properties &

# 停止
bin/kafka-server-stop.sh
```



#### 2 配置

##### 01 server.properties

```ini
# 唯一标识符，整数
broker.id=8
port=9092

# 配置zookeeper地址
# 如果多个kafka集群共用一套zk，则可以考虑使用 chroot
zookeeper.connect=hello.com:2181,world.com:2181,panda.com:2181

# log参数
# 日志位置：一定配置多块磁盘，以提升读写性能，以支持failover
log.dirs=/home/disk4/data/kafka/kafka-logs,/home/disk5/data/kafka/kafka-logs
log.retention.hours=720		# 消息被保存的最长时间，默认168h=7天
#log.retention.bytes=-1			# broker为消息保存的总磁盘容量大小，默认-1，即不限制
#log.flush.scheduler.interval.ms = 9223372036854775807 # 间隔落盘时间, 默认这个大值意味着让OS来决定

# follower超过10秒没向leader发起fetch请求，就从ISR中移除（满足条件后会再加入到ISR中）
#replica.lag.time.max.ms=10000	
# follower的消息落后于leader超4000条，就从ISR中移除（满足条件后会再加入到ISR中）
#replica.lag.max.messages=4000


# 确保ISR中的最小副本数为2, 防止leader挂掉后丢失消息
min.insync.replicas = 2
# 自动创建的topic的replication.factor, 建议配置min.insync.replicas+1, 默认值1
default.replication.factor=3 
# __consumer_offsets这个topic的replication.factor, 默认值3
# offsets.topic.replication.factor=3

##################### leader参数 #####################
# 禁止进度落后的副本竞选成为leader，否则可能会导致数据丢失
unclean.leader.election.enable=false

# 禁止定期换leader
auto.leader.rebalance.enable=false

##################### topic参数 #####################
# 禁止自动创建topic，应该由运维按部门进行分配
auto.create.topics.enable=false

# 每个topic的默认分区数	
num.partitions=12

##################### 其它参数 #####################
# 单个消息的大小上限，默认值~1M，先调整为20M
message.max.bytes=20971520
```



##### 02 producer.properties（暂未调整）

```ini
# 0：异步发送，不等待leader回复，producer立即返回，消息有可能丢失
# 1：produer等待leader返回的ack消息后再返回，丢会重发
# -1：所有的follower都同步消息成功后leader才发送ack给produer，高可靠
request.required.asks=-1
```



#### 3 命令行

```shell
# 进入docker
docker exec --workdir /opt/kafka/bin/ -it kafka sh

# topics
./kafka-topics.sh --bootstrap-server localhost:9092 --list
./kafka-topics.sh --bootstrap-server localhost:9092 --create --topic top-up

./kafka-topics.sh --version
./kafka-topics.sh --bootstrap-server localhost:9092 --delete --topic top-up

# producer
./kafka-console-producer.sh --bootstrap-server localhost:9092 --topic top-up

# consumer
./kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic top-up --from-beginning
./kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic top-up --from-beginning --group group_name
```





----

#### 9 References

1. [Kafka集群部署指南](https://ken.io/note/kafka-cluster-deploy-guide)
2. [Kafka defaults that you should re-consider](https://www.javierholguera.com/2018/06/13/kafka-defaults-that-you-should-re-consider-i/) 