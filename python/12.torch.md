







#### 01 basics

1. dropout: 防止过拟合
2. hidden_size: 神经网络的层数, bert-base为768
3. labels: 分类任务的分类标签, bert在finetune时需要指定
4. last_hidden_state: 模型最后一层输出的隐藏层序列状态, 即整个文本计算之后每个token的结果信息
5. logits: 在CNN中, logits指最后一层神经层输出的score, 需应用softmax激活函数转化为概率分布(和为1)
6. 



```python
import numpy as np
import torch
n = np.arange(18).reshape(3, 2, 3)
a = torch.arange(18).reshape(3, 2, 3)
print(a)

# 在dim=0切3刀, 在dim=1切2刀, 在dim=2切3刀
tensor([[[ 0,  1,  2],
         [ 3,  4,  5]],

        [[ 6,  7,  8],
         [ 9, 10, 11]],

        [[12, 13, 14],
         [15, 16, 17]]])

```





