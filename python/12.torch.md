







#### 01 basics

1. dropout: 随机丢弃, 防止过拟合
2. hidden_size: 神经网络的层数, bert-base为768
3. labels: 分类任务的分类标签, bert在finetune时需要指定
4. last_hidden_state: 模型最后一层输出的隐藏层序列状态, 即整个文本计算之后每个token的结果信息
5. logits: 在CNN中, logits指最后一层神经层输出的score, 需用softmax激活函数转为概率分布(和为1)
6. 



```python
import numpy as np
import torch
n = np.arange(18).reshape(3, 2, 3)
a = torch.arange(18).reshape(3, 2, 3)
print(a)

# 在dim=0切3刀, 在dim=1切2刀, 在dim=2切3刀
tensor([[[ 0,  1,  2],
         [ 3,  4,  5]],

        [[ 6,  7,  8],
         [ 9, 10, 11]],

        [[12, 13, 14],
         [15, 16, 17]]])

```



#### 02 audio



```python
# 加载的音频数据是 [channels, samples]　的格式
# sr是sample rate
audio, sr = torchaudio.load(str(input_path))
if audio.shape[0] > 1:
    # 如果channels是多声道，则转化成单声道的，方便进一步处理
    audio = audio.mean(0, keepdim=True)

# 按model指定的sample_rate对audio进行重采样
audio = torchaudio.functional.resample(
    audio, sr, model.spec_transform.sample_rate
)

#　转换成[0, channels, samples]的格式，并转到device上，
audios = audio[None].to(device)
logger.info(
    f"Loaded audio with {audios.shape[2] / model.spec_transform.sample_rate:.2f} seconds"
)

# VQ Encoder
audio_lengths = torch.tensor([audios.shape[2]], device=device, dtype=torch.long)
indices = model.encode(audios, audio_lengths)[0][0]

logger.info(f"Generated indices of shape {indices.shape}")

# 把indices转到cpu的数据，以numpy的格式存储。进一步可以使用torch.from_numpy()从npy文件加载这些数据
np.save(output_path.with_suffix(".npy"), indices.cpu().numpy())
```













































